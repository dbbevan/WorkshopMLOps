{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Analyse ML Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://github.com/retkowsky/images/blob/master/AzureMLservicebanniere.png?raw=true'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-12 08:09:08.401692\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"framingham.csv\"):\n",
    "  os.remove(\"framingham.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-12 08:09:33--  https://raw.githubusercontent.com/retkowsky/WorkshopMLOps/master/framingham.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.36.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.36.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 191805 (187K) [text/plain]\n",
      "Saving to: ‘framingham.csv’\n",
      "\n",
      "framingham.csv      100%[===================>] 187.31K  --.-KB/s    in 0.006s  \n",
      "\n",
      "2020-03-12 08:09:33 (28.1 MB/s) - ‘framingham.csv’ saved [191805/191805]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://raw.githubusercontent.com/retkowsky/WorkshopMLOps/master/framingham.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('framingham.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke = (df['currentSmoker']==1)\n",
    "df.loc[smoke,'cigsPerDay'] = df.loc[smoke,'cigsPerDay'].fillna(df.loc[smoke,'cigsPerDay'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BPMeds'].fillna(0, inplace = True)\n",
    "df['glucose'].fillna(df.glucose.mean(), inplace = True)\n",
    "df['totChol'].fillna(df.totChol.mean(), inplace = True)\n",
    "df['education'].fillna(1, inplace = True)\n",
    "df['BMI'].fillna(df.BMI.mean(), inplace = True)\n",
    "df['heartRate'].fillna(df.heartRate.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modélisation Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.iloc[:,:-1]\n",
    "result = df.iloc[:,-1] # the last column is what we are about to forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partitionnement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, result, test_size = 0.2, random_state = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "        max_features=None, norm_order=1, prefit=False, threshold=0.12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a selector object that will use the random forest classifier to identify\n",
    "# features that have an importance of more than 0.12\n",
    "sfm = SelectFromModel(clf, threshold=0.12)\n",
    "\n",
    "# Train the selector\n",
    "sfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "prevalentHyp\n",
      "sysBP\n",
      "glucose\n"
     ]
    }
   ],
   "source": [
    "feat_labels = list(features.columns.values) # creating a list with features' names\n",
    "for feature_list_index in sfm.get_support(indices=True):\n",
    "    print(feat_labels[feature_list_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 1 (0.242214)\n",
      "2. feature 10 (0.200736)\n",
      "3. feature 14 (0.152858)\n",
      "4. feature 7 (0.139117)\n",
      "5. feature 11 (0.105004)\n",
      "6. feature 0 (0.034898)\n",
      "7. feature 12 (0.034277)\n",
      "8. feature 4 (0.022181)\n",
      "9. feature 5 (0.016595)\n",
      "10. feature 8 (0.015724)\n",
      "11. feature 9 (0.014800)\n",
      "12. feature 13 (0.009745)\n",
      "13. feature 2 (0.007321)\n",
      "14. feature 6 (0.004530)\n",
      "15. feature 3 (0.000000)\n"
     ]
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With only imporant features. Can check X_important_train.shape[1]\n",
    "X_important_train = sfm.transform(X_train)\n",
    "X_important_test = sfm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_important = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n",
    "clf_important.fit(X_important_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Métriques du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Classification Report\n",
      "============================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91       724\n",
      "           1       0.27      0.10      0.14       124\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       848\n",
      "   macro avg       0.56      0.53      0.52       848\n",
      "weighted avg       0.77      0.83      0.79       848\n",
      "\n",
      "\n",
      "============================\n",
      "Confusion Matrix\n",
      "============================\n",
      "[[691  33]\n",
      " [112  12]]\n",
      "\n",
      "============================\n",
      "ROC\n",
      "============================\n",
      "0.6730306540723578\n",
      "\n",
      "============================\n",
      "Accuracy score\n",
      "============================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8290094339622641"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_y_4 = clf_important.predict(X_important_test)\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Classification Report\")\n",
    "print(\"============================\")\n",
    "print(classification_report(y_test, predictions_y_4))\n",
    "print(\"\")\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"============================\")\n",
    "print(confusion_matrix(y_test, predictions_y_4))\n",
    "print(\"\")\n",
    "\n",
    "# Under ROC curve\n",
    "print(\"============================\")\n",
    "print(\"ROC\")\n",
    "print(\"============================\")\n",
    "prob_y_4 = clf_important.predict_proba(X_important_test)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print(roc_auc_score(y_test, prob_y_4))\n",
    "print(\"\")\n",
    "\n",
    "print(\"============================\")\n",
    "print(\"Accuracy score\")\n",
    "print(\"============================\")\n",
    "accuracy_score(y_test, predictions_y_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export du Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./outputs/model', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './outputs/model/chd-rf-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved in ././outputs/model/ folder\n",
      "Saving model files completed.\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(clf_important, open(filename, 'wb'))\n",
    "print(\"model saved in ././outputs/model/ folder\")\n",
    "print(\"Saving model files completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat : [1]\n"
     ]
    }
   ],
   "source": [
    "age = 61\n",
    "prevalentHyp = 1\n",
    "sysBP = 150\n",
    "glucose = 103\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "print(\"Résultat :\", loaded_model.predict([[age, prevalentHyp, sysBP, glucose]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat : [0]\n"
     ]
    }
   ],
   "source": [
    "age = 43\n",
    "prevalentHyp = 1\n",
    "sysBP = 180\n",
    "glucose = 99\n",
    " \n",
    "print(\"Résultat :\", loaded_model.predict([[age, prevalentHyp, sysBP, glucose]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat : [1]\n"
     ]
    }
   ],
   "source": [
    "age = 63\n",
    "prevalentHyp = 0\n",
    "sysBP = 138\n",
    "glucose = 85\n",
    " \n",
    "print(\"Résultat :\", loaded_model.predict([[age, prevalentHyp, sysBP, glucose]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat : [0]\n"
     ]
    }
   ],
   "source": [
    "age = 52\n",
    "prevalentHyp = 1\n",
    "sysBP = 141\n",
    "glucose = 75\n",
    " \n",
    "print(\"Résultat :\", loaded_model.predict([[age, prevalentHyp, sysBP, glucose]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = loaded_model.predict([[61, 1, 150, 103],[43, 1, 180, 99],[63,0,138,85]])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Lets try in the format in the way the REST service we operationalize the model to, expects it\n",
    "import json\n",
    "\n",
    "to_be_scored_json = {\"data\":[[61, 1, 150, 103],[43, 1, 180, 99],[63,0,138,85]]}\n",
    "input_data_json = json.dumps(to_be_scored_json)\n",
    "\n",
    "to_be_scored_list = json.loads(input_data_json)[\"data\"]\n",
    "to_be_scored_list=np.array(to_be_scored_list)\n",
    "print(loaded_model.predict(to_be_scored_list).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
